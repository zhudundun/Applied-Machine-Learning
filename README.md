# Applied-Machine-Learning

### HW1: Naive Bayes classifier
The UC Irvine machine learning data repository hosts a collection of data on student performance in Portugal.

Build and evaluate a naive Bayes classifier from scratch for prediction. 

For binary attributes, use a binomial model. For numeric attributes, use a normal model or multinomial model and compare. 

### HW1: Support vector machine
The UC Irvine machine learning data repository hosts a collection of data on adult income. 

Write a program to train a support vector machine from scratch on this data using stochastic gradient descent. 


### HW3 Principal components analysis
Obtain the iris dataset from the UC Irvine machine learning data repository. Investigate the use of principal components to smooth data.

### HW4 Hierarchical clustering
The MNIST dataset is a dataset of 60,000 training and 10,000 test examples of handwritten digits. The dataset consists of 28 Ã— 28 images.

Use hierarchical k-means to build a dictionary of image patches. Now use dictionary to find the closest center to each patch, and construct a histogram of patches for each test image. 

Train a classifier using this histogram of patches representation. Evaluate this classifier on the test data.

### HW5 Gaussian mixture model
Image segmentation is an important application of clustering.Model the pixel values as a mixture of normal distributions and using EM. 

Display the image obtained by replacing each pixel with the mean of its cluster center. 

Construct a figure showing the weights linking each pixel to each cluster center.

### HW7 Mean field inference for binary images
The MNIST dataset consists of 60, 000 images of handwritten digits. Obtain the MNIST training set, and binarize the first 500 images by mapping any value below .5 to -1 and any value above to 1. For each image, create a noisy version by randomly flipping 2% of the bits.

Now denoise each image using a Boltzmann machine model and mean field inference. 



